{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNs.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "O227JLfBitD2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "prepare datase"
      ]
    },
    {
      "metadata": {
        "id": "rIGqayI9cx7q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "eb3858b5-864c-4eaa-89c3-681c885a3b43"
      },
      "cell_type": "code",
      "source": [
        "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"Functions for downloading and reading MNIST data.\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# pylint: disable=unused-import\n",
        "import gzip\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import numpy\n",
        "from six.moves import urllib\n",
        "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
        "# pylint: enable=unused-import\n",
        "\n",
        "import tensorflow as tf\n",
        "mnist = read_data_sets(\"/tmp/data/\", one_hot=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-35119369d920>:20: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o3aMCRg2fRUP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f62cc3be-4347-4449-9f06-ff4ce55a4959"
      },
      "cell_type": "code",
      "source": [
        "print (mnist)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f223b310790>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f223b310810>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f223b3105d0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qjeHQRBki8Ls",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "define variables and conditions"
      ]
    },
    {
      "metadata": {
        "id": "CTiLFnSpfMv6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "training_iters = 100000\n",
        "batch_size = 128\n",
        "display_step = 10\n",
        "n_input = 784\n",
        "n_classes = 10\n",
        "dropout = 0.75"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JoLLW8H4jGRK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "define x, y"
      ]
    },
    {
      "metadata": {
        "id": "Y6q2l4Ryfz3t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32, [None, n_input])\n",
        "_X = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
        "y = tf.placeholder(tf.float32, [None, n_classes])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7sskd5SGjM_x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "shared weights and bias"
      ]
    },
    {
      "metadata": {
        "id": "0Pu2ShX3gau1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wc1 = tf.Variable(tf.random_normal([5, 5, 1, 32]))\n",
        "bc1 = tf.Variable(tf.random_normal([32]))\n",
        "\n",
        "def conv2d(img, w, b):\n",
        "  return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(img, w, strides=[1, 1, 1, 1], padding='SAME'),b))\n",
        "\n",
        "conv1 = conv2d(_X,wc1,bc1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sj10qiW3jS8v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "convolutional layer"
      ]
    },
    {
      "metadata": {
        "id": "sXw58vuih3hR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def max_pool(img, k):\n",
        "  return tf.nn.max_pool(img, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
        "\n",
        "conv1 = max_pool(conv1, k=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "40tCQFy5jWih",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "dropout to avoid overfitting"
      ]
    },
    {
      "metadata": {
        "id": "rYrRePqoifwt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "keep_prob = tf. placeholder(tf.float32)\n",
        "conv1 = tf.nn.dropout(conv1,keep_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CHotiZaCji1J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "second convolutional layer"
      ]
    },
    {
      "metadata": {
        "id": "T-bDiR8LjmGH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wc2 = tf.Variable(tf.random_normal([5, 5, 32, 64]))\n",
        "bc2 = tf.Variable(tf.random_normal([64]))\n",
        "conv2 = conv2d(conv1,wc2,bc2)\n",
        "conv2 = max_pool(conv2, k=2)\n",
        "conv2 = tf.nn.dropout(conv2, keep_prob)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tw87cY18kHUB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Densely connected layer"
      ]
    },
    {
      "metadata": {
        "id": "Cgr-K8rRkIJY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wd1 = tf.Variable(tf.random_normal([7*7*64, 1024]))\n",
        "bd1 = tf.Variable(tf.random_normal([1024]))\n",
        "dense1 = tf.reshape(conv2, [-1, wd1.get_shape().as_list()[0]])\n",
        "dense1 = tf.nn.relu(tf.add(tf.matmul(dense1, wd1),bd1))\n",
        "dense1 = tf.nn.dropout(dense1, keep_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rAL-Xsm4kU-C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Readout layer"
      ]
    },
    {
      "metadata": {
        "id": "-V4fLkjCkYMQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wout = tf.Variable(tf.random_normal([1024, n_classes]))\n",
        "bout = tf.Variable(tf.random_normal([n_classes]))\n",
        "pred = tf.add(tf.matmul(dense1, wout), bout)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SNxjHs2nkoKT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Testing and training the model"
      ]
    },
    {
      "metadata": {
        "id": "khhCSOGykqB0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cWkt5hZHk76f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Launching the session"
      ]
    },
    {
      "metadata": {
        "id": "PJx1gUddk9R0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1478
        },
        "outputId": "8bc66dd6-8798-4e63-a4bc-80ba1b075ae7"
      },
      "cell_type": "code",
      "source": [
        "init = tf.initialize_all_variables()\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  step = 1\n",
        "  while step * batch_size < training_iters:\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "    sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys, keep_prob:  dropout})\n",
        "    if step % display_step == 0:\n",
        "      acc = sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})\n",
        "      loss = sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})\n",
        "      print (\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
        "    step += 1\n",
        "  print (\"Optimization Finished!\")\n",
        "  print (\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: mnist.test.images[:256], y: mnist.test.labels[:256], keep_prob: 1.}))\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "Iter 1280, Minibatch Loss= 31807.355469, Training Accuracy= 0.28906\n",
            "Iter 2560, Minibatch Loss= 17011.226562, Training Accuracy= 0.24219\n",
            "Iter 3840, Minibatch Loss= 10394.257812, Training Accuracy= 0.46875\n",
            "Iter 5120, Minibatch Loss= 5458.902344, Training Accuracy= 0.60156\n",
            "Iter 6400, Minibatch Loss= 9624.007812, Training Accuracy= 0.56250\n",
            "Iter 7680, Minibatch Loss= 4162.286133, Training Accuracy= 0.71094\n",
            "Iter 8960, Minibatch Loss= 3302.252930, Training Accuracy= 0.75000\n",
            "Iter 10240, Minibatch Loss= 3222.419922, Training Accuracy= 0.81250\n",
            "Iter 11520, Minibatch Loss= 3892.108154, Training Accuracy= 0.78906\n",
            "Iter 12800, Minibatch Loss= 3230.108643, Training Accuracy= 0.79688\n",
            "Iter 14080, Minibatch Loss= 3302.411865, Training Accuracy= 0.80469\n",
            "Iter 15360, Minibatch Loss= 3704.164795, Training Accuracy= 0.84375\n",
            "Iter 16640, Minibatch Loss= 3784.021973, Training Accuracy= 0.78906\n",
            "Iter 17920, Minibatch Loss= 4796.196289, Training Accuracy= 0.78125\n",
            "Iter 19200, Minibatch Loss= 3108.481445, Training Accuracy= 0.82812\n",
            "Iter 20480, Minibatch Loss= 1622.107910, Training Accuracy= 0.89062\n",
            "Iter 21760, Minibatch Loss= 1746.315186, Training Accuracy= 0.88281\n",
            "Iter 23040, Minibatch Loss= 2406.491943, Training Accuracy= 0.82031\n",
            "Iter 24320, Minibatch Loss= 1365.530396, Training Accuracy= 0.84375\n",
            "Iter 25600, Minibatch Loss= 1075.366455, Training Accuracy= 0.89844\n",
            "Iter 26880, Minibatch Loss= 2257.300049, Training Accuracy= 0.86719\n",
            "Iter 28160, Minibatch Loss= 1440.622559, Training Accuracy= 0.89844\n",
            "Iter 29440, Minibatch Loss= 2583.138672, Training Accuracy= 0.82812\n",
            "Iter 30720, Minibatch Loss= 1687.824341, Training Accuracy= 0.83594\n",
            "Iter 32000, Minibatch Loss= 2510.120850, Training Accuracy= 0.80469\n",
            "Iter 33280, Minibatch Loss= 1240.034790, Training Accuracy= 0.91406\n",
            "Iter 34560, Minibatch Loss= 1646.993408, Training Accuracy= 0.89062\n",
            "Iter 35840, Minibatch Loss= 1921.144897, Training Accuracy= 0.87500\n",
            "Iter 37120, Minibatch Loss= 1094.800049, Training Accuracy= 0.91406\n",
            "Iter 38400, Minibatch Loss= 1324.395020, Training Accuracy= 0.89844\n",
            "Iter 39680, Minibatch Loss= 1453.844604, Training Accuracy= 0.85938\n",
            "Iter 40960, Minibatch Loss= 1275.696289, Training Accuracy= 0.88281\n",
            "Iter 42240, Minibatch Loss= 1807.570801, Training Accuracy= 0.84375\n",
            "Iter 43520, Minibatch Loss= 1549.550293, Training Accuracy= 0.87500\n",
            "Iter 44800, Minibatch Loss= 785.533569, Training Accuracy= 0.89844\n",
            "Iter 46080, Minibatch Loss= 460.909180, Training Accuracy= 0.95312\n",
            "Iter 47360, Minibatch Loss= 2260.319336, Training Accuracy= 0.88281\n",
            "Iter 48640, Minibatch Loss= 1014.612671, Training Accuracy= 0.91406\n",
            "Iter 49920, Minibatch Loss= 1286.375977, Training Accuracy= 0.92188\n",
            "Iter 51200, Minibatch Loss= 1006.073730, Training Accuracy= 0.89844\n",
            "Iter 52480, Minibatch Loss= 1422.164551, Training Accuracy= 0.90625\n",
            "Iter 53760, Minibatch Loss= 927.881958, Training Accuracy= 0.92188\n",
            "Iter 55040, Minibatch Loss= 393.666504, Training Accuracy= 0.93750\n",
            "Iter 56320, Minibatch Loss= 631.888794, Training Accuracy= 0.91406\n",
            "Iter 57600, Minibatch Loss= 1909.845093, Training Accuracy= 0.87500\n",
            "Iter 58880, Minibatch Loss= 1107.859497, Training Accuracy= 0.91406\n",
            "Iter 60160, Minibatch Loss= 1041.970215, Training Accuracy= 0.91406\n",
            "Iter 61440, Minibatch Loss= 1387.831543, Training Accuracy= 0.88281\n",
            "Iter 62720, Minibatch Loss= 462.522858, Training Accuracy= 0.92969\n",
            "Iter 64000, Minibatch Loss= 671.023926, Training Accuracy= 0.92969\n",
            "Iter 65280, Minibatch Loss= 725.817383, Training Accuracy= 0.89062\n",
            "Iter 66560, Minibatch Loss= 567.583618, Training Accuracy= 0.92969\n",
            "Iter 67840, Minibatch Loss= 840.837891, Training Accuracy= 0.90625\n",
            "Iter 69120, Minibatch Loss= 637.228210, Training Accuracy= 0.92969\n",
            "Iter 70400, Minibatch Loss= 622.240234, Training Accuracy= 0.90625\n",
            "Iter 71680, Minibatch Loss= 769.534058, Training Accuracy= 0.92969\n",
            "Iter 72960, Minibatch Loss= 657.970337, Training Accuracy= 0.90625\n",
            "Iter 74240, Minibatch Loss= 319.612396, Training Accuracy= 0.93750\n",
            "Iter 75520, Minibatch Loss= 561.716309, Training Accuracy= 0.92188\n",
            "Iter 76800, Minibatch Loss= 1022.002319, Training Accuracy= 0.91406\n",
            "Iter 78080, Minibatch Loss= 491.529114, Training Accuracy= 0.93750\n",
            "Iter 79360, Minibatch Loss= 810.901245, Training Accuracy= 0.87500\n",
            "Iter 80640, Minibatch Loss= 725.745483, Training Accuracy= 0.89844\n",
            "Iter 81920, Minibatch Loss= 528.396118, Training Accuracy= 0.92969\n",
            "Iter 83200, Minibatch Loss= 254.901489, Training Accuracy= 0.95312\n",
            "Iter 84480, Minibatch Loss= 841.302979, Training Accuracy= 0.89062\n",
            "Iter 85760, Minibatch Loss= 527.888550, Training Accuracy= 0.91406\n",
            "Iter 87040, Minibatch Loss= 569.534912, Training Accuracy= 0.95312\n",
            "Iter 88320, Minibatch Loss= 539.936584, Training Accuracy= 0.92969\n",
            "Iter 89600, Minibatch Loss= 379.375153, Training Accuracy= 0.95312\n",
            "Iter 90880, Minibatch Loss= 591.594238, Training Accuracy= 0.92188\n",
            "Iter 92160, Minibatch Loss= 464.153564, Training Accuracy= 0.92188\n",
            "Iter 93440, Minibatch Loss= 606.358154, Training Accuracy= 0.93750\n",
            "Iter 94720, Minibatch Loss= 245.806519, Training Accuracy= 0.96094\n",
            "Iter 96000, Minibatch Loss= 312.105652, Training Accuracy= 0.96875\n",
            "Iter 97280, Minibatch Loss= 248.457428, Training Accuracy= 0.93750\n",
            "Iter 98560, Minibatch Loss= 421.442352, Training Accuracy= 0.94531\n",
            "Iter 99840, Minibatch Loss= 565.177734, Training Accuracy= 0.92188\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.97265625\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
